# LeyClara.IA üìú‚öñÔ∏è

**LeyClara.IA** es un asistente legal inteligente dise√±ado para democratizar el acceso a la informaci√≥n jur√≠dica. Su objetivo es tomar documentos legales complejos (leyes, contratos, sentencias) y explicarlos en un lenguaje sencillo y accesible para cualquier persona, "como si tuviera 5 a√±os".

## üß† Arquitectura T√©cnica: RAG (Retrieval-Augmented Generation)

Este proyecto utiliza una arquitectura **RAG** en lugar de un chat simple con IA.

### ¬øPor qu√© RAG?
Los modelos de lenguaje (LLMs) como GPT o Gemini tienen dos grandes limitaciones:
1.  **Alucinaciones:** Pueden inventar datos si no saben la respuesta.
2.  **Desconocimiento:** No conocen tus documentos privados o leyes locales espec√≠ficas que no estaban en su entrenamiento.

RAG soluciona esto permitiendo que la IA "lea" tus documentos antes de responder. El flujo es:
1.  **B√∫squeda (Retrieval):** El sistema busca en tu biblioteca los p√°rrafos exactos que responden a tu pregunta.
2.  **Generaci√≥n (Augmented Generation):** Env√≠a esos p√°rrafos a la IA y le dice: *"Usa SOLO esta informaci√≥n para responder al usuario"*. Esto garantiza respuestas precisas y basadas en evidencia real.

## üìö El Rol de ChromaDB (Nuestra "Biblioteca")

Para que el sistema sea r√°pido y eficiente, utilizamos **ChromaDB**, una base de datos vectorial.

*   **El Problema:** No podemos enviarle un PDF de 500 p√°ginas a la IA cada vez que hacemos una pregunta. Ser√≠a lento, costoso y exceder√≠a la memoria del modelo.
*   **La Soluci√≥n (ChromaDB):**
    1.  Cuando subes un PDF, lo "cortamos" en pedazos peque√±os.
    2.  Convertimos cada pedazo en una "huella digital matem√°tica" (vector) usando la API de Google Embeddings.
    3.  Guardamos estos vectores en ChromaDB localmente.
    4.  Cuando preguntas, ChromaDB encuentra matem√°ticamente los 6 fragmentos m√°s parecidos a tu pregunta en milisegundos, sin tener que volver a leer todo el documento.

## ‚úÇÔ∏è Estrategia de Chunking (Fragmentaci√≥n)

Una decisi√≥n cr√≠tica de dise√±o fue el tama√±o de los "chunks" (fragmentos de texto).

*   **Configuraci√≥n Actual:** 500 caracteres (con 100 de solapamiento).
*   **¬øPor qu√© este tama√±o?**
    *   Inicialmente probamos con 1000 caracteres, pero el sistema perd√≠a detalles espec√≠ficos (como n√∫meros de art√≠culos o t√≠tulos cortos) porque se "dilu√≠an" en tanto texto.
    *   Al reducirlo a **500 caracteres**, logramos un efecto "lupa": cada fragmento es m√°s espec√≠fico y preciso. Esto permite encontrar "agujas en un pajar" (detalles puntuales) con mucha mayor eficacia.

## üß© El Rol de LangChain (El "Pegamento")

**LangChain** es el framework que conecta todas las piezas del rompecabezas. Act√∫a como el orquestador que:

1.  **Carga y Procesa:** Usa herramientas para leer PDFs y dividirlos en chunks.
2.  **Conecta:** Sirve de puente entre tu base de datos local (ChromaDB) y la API de Google (Gemini).
3.  **Gestiona el Flujo:** Cuando haces una pregunta, LangChain ejecuta autom√°ticamente una "cadena" de pasos: buscar contexto -> construir el prompt -> consultar a la IA -> entregar la respuesta.

Sin LangChain, tendr√≠amos que escribir manualmente todo el c√≥digo para conectar estos servicios dispares.

## üõ†Ô∏è Tecnolog√≠as

*   **Backend:** Python, FastAPI.
*   **IA:** Google Gemini 1.5 Flash (v√≠a LangChain).
*   **Base de Datos:** ChromaDB (Vector Store).
*   **Frontend:** React, TailwindCSS.
*   **Infraestructura:** Docker & Docker Compose.

## üöÄ C√≥mo Ejecutarlo

### Desarrollo Local

1.  Clona el repositorio.
2.  Crea un archivo `.env` en la ra√≠z con tus claves de API (ver `.env.example`).
3.  Crea un archivo `frontend/.env` con:
    ```env
    VITE_API_URL=http://localhost:8000
    ```
4.  Ejecuta:
    ```bash
    docker-compose up --build
    ```
5.  Abre `http://localhost:3000` y empieza a subir documentos.

### üåê Despliegue en la Nube

#### Opci√≥n 1: Google Compute Engine (Recomendado - Con Persistencia)

Para despliegue en producci√≥n con almacenamiento persistente:

```bash
# Ver instrucciones completas
cat .agent/workflows/deploy-to-gce.md
```

**Ventajas:**
- ‚úÖ Datos persistentes (ChromaDB, documentos subidos)
- ‚úÖ Costos predecibles (~$15-30/mes)
- ‚úÖ Control total del servidor

#### Opci√≥n 2: Railway

Railway ofrece $5/mes de cr√©dito gratuito, suficiente para proyectos peque√±os/medianos.

**Gu√≠a R√°pida:**
1. Crea una cuenta en [railway.app](https://railway.app)
2. Conecta tu repositorio de GitHub
3. Sigue la gu√≠a: [`RAILWAY_DEPLOY.md`](RAILWAY_DEPLOY.md)
4. Usa el checklist: [`RAILWAY_CHECKLIST.md`](RAILWAY_CHECKLIST.md)

**Recursos:**
- üìñ [Gu√≠a Completa de Despliegue](.agent/workflows/deploy_to_railway.md)
- üîß [Variables de Entorno](RAILWAY_ENV_VARS.md)
- ‚úÖ [Checklist de Despliegue](RAILWAY_CHECKLIST.md)

#### Opci√≥n 3: Google Cloud Run (Stateless)

Para despliegue r√°pido sin persistencia:

```bash
# Ver instrucciones
cat .agent/workflows/deploy_to_cloud_run.md
```

**Limitaciones:**
- ‚ö†Ô∏è Los datos se pierden al reiniciar
- ‚ö†Ô∏è No recomendado para producci√≥n

#### Otras Opciones

- **Render**: Alternativa gratuita similar a Railway
- **Fly.io**: Excelente para aplicaciones Docker
